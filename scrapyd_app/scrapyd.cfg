[scrapyd]
eggs_dir    = eggs
logs_dir    = logs
items_dir   = items
jobs_to_keep = 5
dbs_dir     = dbs
max_proc    = 0
max_proc_per_cpu = 4
finished_to_keep = 100
poll_interval = 5.0
http_port   = 6800
debug       = off
runner      = scrapyd.runner
application = scrapyd.app.application
launcher    = scrapyd.launcher.Launcher
webroot     = scrapyd.website.Root

[services]
schedule.json     = scrapyd.webservice.Schedule
cancel.json       = scrapyd.webservice.Cancel
addversion.json   = scrapyd.webservice.AddVersion
listprojects.json = scrapyd.webservice.ListProjects
listversions.json = scrapyd.webservice.ListVersions
listspiders.json  = scrapyd.webservice.ListSpiders
delproject.json   = scrapyd.webservice.DeleteProject
delversion.json   = scrapyd.webservice.DeleteVersion
listjobs.json     = scrapyd.webservice.ListJobs
daemonstatus.json = scrapyd.webservice.DaemonStatus

[scrapydweb]
enable_crawl = True
enable_logparser = True
enable_email = False
smtp_server = smtp.example.com
smtp_port = 587
smtp_over_ssl = False
smtp_conn_timeout = 10
email_username = username@example.com
email_password = password
email_to = to@example.com
email_cc = cc@example.com
email_subject = ScrapydWeb
email_interval = 3600
on_job_running_interval = 300
on_job_finished = False
log_level = DEBUG
log_file = scrapydweb.log
print_stats = jobs, cpu, mem, disk, net, err
keep_days = 7
auth_required = False
username = username
password = password
bind = 0.0.0.0
port = 5000
